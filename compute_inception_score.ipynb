{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python382jvsc74a57bd0b826e582c4c6950429e4ab08d565c1942dc747a4b972bee2d4ad610561dc5dd8",
   "display_name": "Python 3.8.2 64-bit ('venv_repos': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils.utils import *\n",
    "from datetime import datetime\n",
    "from evaluation.train_inception_model import SpectrogramInception3\n",
    "from data.preprocessing import AudioProcessor\n",
    "from torch.utils.data import DataLoader\n",
    "from evaluation.metrics.inception_score import InceptionScore\n",
    "from evaluation.inception_models import DEFAULT_FOOTSTEPS_INCEPTION_MODEL\n",
    "from data.audio_transforms import MelScale\n",
    "from tqdm import trange\n",
    "import ipdb\n",
    "\n",
    "from os.path import dirname, realpath, join\n",
    "import logging\n",
    "from data.loaders import get_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model_name\": \"footsteps_inception_model_best_2021-04-29.pt\",\n",
    "    \"comments\": \"inception trained on footsteps dataset\",\n",
    "    \"state_dict_path\": \"evaluation/inception_models/footsteps_inception_model_best_2021-04-29.pt\",\n",
    "    \n",
    "    \"real_samples_path\": \"audio/footsteps_real\",\n",
    "    \"synth_samples_path\": \"audio/footsteps_generated_23-04-2021_15h\",\n",
    "    \n",
    "    \"output_path\": \"evaluation\",\n",
    "    \"output_folder\": \"evaluation_metrics\",\n",
    "    \n",
    "    \"batch_size\": 20,\n",
    "\n",
    "    \"real_samples_loader_config\": {\n",
    "        \"dbname\": \"footsteps\",\n",
    "        \"data_path\": \"audio/footsteps_real/\",\n",
    "        \"criteria\": {},\n",
    "        \"shuffle\": True,\n",
    "        \"tr_val_split\": 1.0\n",
    "    },\n",
    "\n",
    "    \"synth_samples_loader_config\": {\n",
    "        \"dbname\": \"footsteps\",\n",
    "        \"data_path\": \"audio/footsteps_generated_23-04-2021_15h/\",\n",
    "        \"criteria\": {},\n",
    "        \"shuffle\": True,\n",
    "        \"tr_val_split\": 1.0\n",
    "    },\n",
    "    \n",
    "    \"transform_config\": {\n",
    "        \"transform\": \"stft\",\n",
    "        \"fade_out\": True,\n",
    "        \"fft_size\": 1024,\n",
    "        \"win_size\": 1024,\n",
    "        \"n_frames\": 64,\n",
    "        \"hop_size\": 256,\n",
    "        \"log\": False,\n",
    "        \"ifreq\": False,\n",
    "        \"sample_rate\": 16000,\n",
    "        \"audio_length\": 16000\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = config['model_name']\n",
    "state_dict_path = config['state_dict_path']\n",
    "output_path = mkdir_in_path(config['output_path'], config['output_folder'])\n",
    "# output_log = join(output_path, f\"{model_name}_evaluation.log\")\n",
    "# logging.basicConfig(filename=output_log, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Configuring stft transform...\n",
      "Dataset audio/footsteps_real/processed/footsteps_stft/footsteps_stft.pt exists. Reloading...\n",
      "n_real_samples:  720\n",
      "Cuda not available. Running on CPU\n"
     ]
    }
   ],
   "source": [
    "real_samples_loader_config = config['real_samples_loader_config']\n",
    "\n",
    "transform_config = config['transform_config']\n",
    "transform = transform_config['transform']\n",
    "\n",
    "dbname = real_samples_loader_config['dbname']\n",
    "\n",
    "batch_size = config['batch_size']\n",
    "\n",
    "processor = AudioProcessor(**transform_config)\n",
    "\n",
    "loader_module = get_data_loader(dbname)\n",
    "\n",
    "real_samples_loader = loader_module(name=dbname + '_' + transform, preprocessing=processor, **real_samples_loader_config)\n",
    "\n",
    "n_real_samples = len(real_samples_loader)\n",
    "print('n_real_samples: ', n_real_samples)\n",
    "\n",
    "real_samples_data_loader = DataLoader(real_samples_loader,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=True,\n",
    "                                        num_workers=2)\n",
    "\n",
    "device = 'cuda' if GPU_is_available() else 'cpu'\n",
    "\n",
    "state_dict = torch.load(state_dict_path, map_location=device)\n",
    "inception_footsteps = SpectrogramInception3(state_dict['fc.weight'].shape[0], aux_logits=False)\n",
    "inception_footsteps.load_state_dict(state_dict)\n",
    "inception_footsteps = inception_footsteps.to(device)\n",
    "\n",
    "mel = MelScale(sample_rate=transform_config['sample_rate'],\n",
    "                fft_size=transform_config['fft_size'],\n",
    "                n_mel=transform_config.get('n_mel', 256),\n",
    "                rm_dc=True)\n",
    "mel = mel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "batch:  0 IS:  5.466772467532699\n",
      "batch:  1 IS:  5.565402963191995\n",
      "batch:  2 IS:  5.488650793942982\n",
      "batch:  3 IS:  5.39592375210772\n",
      "batch:  4 IS:  5.530355001448792\n",
      "batch:  5 IS:  5.511362250136727\n",
      "batch:  6 IS:  5.569491659003954\n",
      "batch:  7 IS:  5.596020796236649\n",
      "batch:  8 IS:  5.571151441673725\n",
      "batch:  9 IS:  5.590743335479327\n",
      "batch:  10 IS:  5.622973009719555\n",
      "batch:  11 IS:  5.640172493268067\n",
      "batch:  12 IS:  5.6603077568569855\n",
      "batch:  13 IS:  5.66947609021406\n",
      "batch:  14 IS:  5.651755544234304\n",
      "batch:  15 IS:  5.645156396813439\n",
      "batch:  16 IS:  5.645800953091852\n",
      "batch:  17 IS:  5.657693016402988\n",
      "batch:  18 IS:  5.6632517700655125\n",
      "batch:  19 IS:  5.635337063481726\n",
      "batch:  20 IS:  5.619325566882319\n",
      "batch:  21 IS:  5.61160862551869\n",
      "batch:  22 IS:  5.626786617103338\n",
      "batch:  23 IS:  5.638231170166783\n",
      "batch:  24 IS:  5.644710638177991\n",
      "batch:  25 IS:  5.651486517388761\n",
      "batch:  26 IS:  5.651865390349704\n",
      "batch:  27 IS:  5.646568196427036\n",
      "batch:  28 IS:  5.65654520139305\n",
      "batch:  29 IS:  5.648272230631572\n",
      "batch:  30 IS:  5.64210269852796\n",
      "batch:  31 IS:  5.642948703685531\n",
      "batch:  32 IS:  5.651994386244292\n",
      "batch:  33 IS:  5.651420305279381\n",
      "batch:  34 IS:  5.659163652255714\n",
      "batch:  35 IS:  5.655938150246428\n"
     ]
    }
   ],
   "source": [
    "is_maker_real_samples = InceptionScore()\n",
    "inception_score_real_samples = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(real_samples_data_loader):\n",
    "        input, labels = data\n",
    "        input.to(device)\n",
    "        input = mel(input.float())\n",
    "        mag_input = F.interpolate(input[:, 0:1], (299, 299))\n",
    "        \n",
    "        preds = inception_footsteps(mag_input.float())\n",
    "        \n",
    "        is_maker_real_samples.updateWithMiniBatch(preds)\n",
    "        inception_score_real_samples.append(is_maker_real_samples.getScore())\n",
    "        \n",
    "        print('batch: ', batch_idx, 'IS: ', is_maker_real_samples.getScore())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_mean = np.mean(inception_score_real_samples)\n",
    "IS_std = np.std(inception_score_real_samples)\n",
    "output_file = f'{output_path}/IS_real_{str(n_real_samples)}_{model_name}_{datetime.now().strftime(\"%d-%m-%y_%H_%M\")}.txt'\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(str(IS_mean) + '\\n')\n",
    "    f.write(str(IS_std))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset audio/footsteps_generated_audio_23-04-2021_15h/processed/footsteps_stft/footsteps_stft.pt exists. Reloading...\n",
      "n_synth_samples:  600\n"
     ]
    }
   ],
   "source": [
    "synth_samples_loader_config = config['synth_samples_loader_config']\n",
    "synth_samples_loader = loader_module(name=dbname + '_' + transform, preprocessing=processor, **synth_samples_loader_config)\n",
    "\n",
    "n_synth_samples = len(synth_samples_loader)\n",
    "print('n_synth_samples: ', n_synth_samples)\n",
    "\n",
    "synth_samples_data_loader = DataLoader(synth_samples_loader,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=True,\n",
    "                                        num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "batch:  0 IS:  4.423433516736267\n",
      "batch:  1 IS:  4.739492460773463\n",
      "batch:  2 IS:  4.780054009446706\n",
      "batch:  3 IS:  4.794234848508344\n",
      "batch:  4 IS:  4.881266130791967\n",
      "batch:  5 IS:  4.897593552653293\n",
      "batch:  6 IS:  4.862352724544507\n",
      "batch:  7 IS:  4.876063027039243\n",
      "batch:  8 IS:  4.918181825607562\n",
      "batch:  9 IS:  4.881561095075136\n",
      "batch:  10 IS:  4.855938893865848\n",
      "batch:  11 IS:  4.82972756597471\n",
      "batch:  12 IS:  4.8460322472590756\n",
      "batch:  13 IS:  4.826242596787764\n",
      "batch:  14 IS:  4.82129198938978\n",
      "batch:  15 IS:  4.85694043447846\n",
      "batch:  16 IS:  4.8497129942704555\n",
      "batch:  17 IS:  4.820516677409252\n",
      "batch:  18 IS:  4.830111953674338\n",
      "batch:  19 IS:  4.839483279567941\n",
      "batch:  20 IS:  4.866913317115213\n",
      "batch:  21 IS:  4.843082987051767\n",
      "batch:  22 IS:  4.835472558572825\n",
      "batch:  23 IS:  4.839133574784806\n",
      "batch:  24 IS:  4.839520770586575\n",
      "batch:  25 IS:  4.8305785479729435\n",
      "batch:  26 IS:  4.84058180697983\n",
      "batch:  27 IS:  4.85227207247436\n",
      "batch:  28 IS:  4.843070559135143\n",
      "batch:  29 IS:  4.833379694691061\n"
     ]
    }
   ],
   "source": [
    "is_maker_synth_samples = InceptionScore()\n",
    "inception_score_synth_samples = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(synth_samples_data_loader):\n",
    "        input, labels = data\n",
    "        input.to(device)\n",
    "        input = mel(input.float())\n",
    "        mag_input = F.interpolate(input[:, 0:1], (299, 299))\n",
    "        \n",
    "        preds = inception_footsteps(mag_input.float())\n",
    "        \n",
    "        is_maker_synth_samples.updateWithMiniBatch(preds)\n",
    "        inception_score_synth_samples.append(is_maker_synth_samples.getScore())\n",
    "        \n",
    "        print('batch: ', batch_idx, 'IS: ', is_maker_synth_samples.getScore())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_mean = np.mean(inception_score_synth_samples)\n",
    "IS_std = np.std(inception_score_synth_samples)\n",
    "output_file = f'{output_path}/IS_synth_{str(n_synth_samples)}_{model_name}_{datetime.now().strftime(\"%d-%m-%y_%H_%M\")}.txt'\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(str(IS_mean) + '\\n')\n",
    "    f.write(str(IS_std))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}